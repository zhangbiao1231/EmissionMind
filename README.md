# âš™ï¸ EmissionMind: Data-Driven Gas Turbine Emission Prediction Framework

---
**EmissionMind** is an intelligent emission prediction system
for $gas turbines$, 
focusing on real-time and high-precision forecasting of NOx, CO, and 
other regulated exhaust components.  
It leverages multi-channels physical sensor data
(e.g., load, pressure, temperature, humidity) to 
construct time-series features and predict emissions under 
varying operating conditions.  
The system is designed for deployment in plant-level 
monitoring, combustion tuning, 
and low-emission optimization scenarios.
---
## ğŸ§  Features

---
- ğŸ“ˆ Predict NOx emissions with physical sensor data only  
- ğŸ” Multi-step emission forecasting using deep sequence models (RNN/GRU/LSTM)  
- ğŸ› ï¸ Modularized pipeline for preprocessing, modeling, evaluation, and deployment  
- ğŸ“¦ Exportable models for industrial integration or edge deployment  
- ğŸ“Š Visualization dashboards for emissions, working conditions, and model diagnostics

## ğŸ“ Project Structure

---
```
Emission/
â”œâ”€â”€ train.py                 # Training script for emission prediction models
â”œâ”€â”€ predict.py               # Inference script
â”œâ”€â”€ val.py                   # Evaluation and validation script
â”œâ”€â”€ model/                  
â”‚   â””â”€â”€ RNN.py               # Optional nerual network frame i.e. RNN, GRU and LSTM.
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ dataloader.py        # Create temperal sequential sets and loading.
â”‚   â”œâ”€â”€ createDatasets.py    # Split segmentations and save to train/valid/test directionary.
â”‚   â”œâ”€â”€ general.py           # Feature engineering and transformation
â”‚   â”œâ”€â”€ preprocess.py        # Feature engineering and transformation
â”‚   â”œâ”€â”€ torch_utils.py       # PyTorch-specific helper functions (e.g., early-stopping)
â”‚   â””â”€â”€ plots/               # Plotting, loss functions, config parsing, etc.
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ min-level/
â”‚   â”‚   â”œâ”€â”€ raw/             # Raw sensor and emission datasets
â”‚   â”‚   â””â”€â”€ processed/       # Preprocessed datasets for training
â”‚   â””â”€â”€ second-level/
â”œâ”€â”€ runs/                    # Model checkpoints, logs, metrics, plots
â”‚   â”œâ”€â”€ train-reg/           
â”‚   â”œâ”€â”€ inference-reg/       
â”‚   â””â”€â”€ val-reg/             
â”œâ”€â”€ environment.yaml         # Conda environment configuration
â”œâ”€â”€ requirements.txt         # pip dependencies (optional)
â””â”€â”€ README.md                # Project documentation
```

## ğŸ“š Technical Details

---
### ğŸ“ 1. Raw Data Overview
- **Source**: Logged sensor data from gas turbine testbed (or simulation outputs)  
- **Sampling Rate**: 1 min (or project-specific)  
- **Features (base)**:
  - `load`, `diffusion_valve_feedback`, `exhaust_temp`, 
  - `compressor_inlet_temp`, `turbine_exhaust_temp_10B`, 
  - `amb_temperature`,`NG_inlet_temp`, `exhaust_temp`, etc.
- **Labels**:
  - `NOx_in_flue_gas` (i.e. NOx)
- **Size**:
  - N test runs Ã— T time steps Ã— D input features

> _Note: Missing values interpolated; outliers removed using IQR filtering._
---
### ğŸ§¹ 2. Data Preprocessing
- **Cleaning**:
  - Remove Nulls and duplicates
  - Clip or mask physically invalid values (e.g., NOx < 0.0 ppm)
- **Normalization**:
  - Per-feature Min-Max scaling or StandardScaler
- **Segmentation**:
  - Split with `time_col=Time`, `freq = 1min`
- **Label Strategy**:
  - Predict next-step emission level (regression)
  - Optional: multi-step average prediction
- **Feature Engineering**:
  - valve_share, etc.
  - $\Delta$T, $\Delta$P,
  - Rolling statistics (e.g., mean, std, gradient)

---
### ğŸ§  3. Model Architecture
- **Base Model**: GRU-based sequence regression
- **Input Format**: `[batch_size, num-steps, num_features]`
- **Architecture**:``` Input â†’ GRU â†’ FC â†’ Digital Prediction```
- **Variants to Explore**:
  - GRU, LSTM, or RNN
  - Temporal Convolutional Network (TCN)
  - Hybrid CNN + RNN for early feature extraction

---
### âš™ï¸ 4. Hyperparameters & Training Settings
| Parameter           | Value                             |
|---------------------|-----------------------------------|
| Batch Size          | 32                                |
| Number Steps        | 10/20/30                          |
| Number Hiddens      | 32/64/96                          |
| RNN Layers          | 2                                 |
| Dropout             | 0.5                               |
| Optimizer           | Adam                              |
| Learning Rate       | 1e-3                              |
| Epochs              | 1000                              |
| Loss Function       | MSE (per output)                  |
| Early Stopping      | Patience = 20                     |
| Learning Rate Decay | StepLR(lr_period=50,lr_decay=0.9) |

> _All training runs are logged under `runs/`, including checkpoints and loss/metric plots._

---
## ğŸ› ï¸ Installation

---
Clone the repository and create the Conda environment:
```
git clone git@github.com:zhangbiao1231/EmissionMind.git
cd EmissionMind
conda env create -f environment.yaml
conda activate emission_env
```
if you prefer pip:
```
pip install -r requirements.txt
```
## ğŸš€ Getting Started

### ğŸ§¹ Preprocess data and generate training sequences
```
python3 utils/dataLoader.py 
--filepath datasets/GT2_2024_selected_features_1min.csv
--input datasets/min-level/raw
--output datasets/min-level/processed
--ratios (0.75, 0.15, 0.1)
```
### ğŸ‹ï¸ Train the emission prediction model
```
python3 train.py --model-name gru --num-steps 20 --num-hiddens 64 
```
### ğŸ” Run validation on val data
```
python3 val.py 
--data datasets/min-level/processed 
--weights runs/train-reg/exp18/best.pt 
```
### ğŸ” Run inference on test data
```
python3 predict.py 
--source datasets/min-level/processed/test (or .../test/xx.csv ) 
--weights runs/train-reg/exp18/best.pt 
```
## ğŸ“Š Example Output

---
### ğŸ“„ Inference Log (Terminal Output)

``` 
Start processing file: XXX.csv
XXX.csv Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 599/599 [00:10<00:00, 100.22it/s]
FileName    Quantities   MAE   RMSE   R2   UnitTime
----------------------------------------------------
XX.csv         196       3.49  4.75  0.14  0.31        
XX.csv         589       1.56  2.21  0.60  0.30        
----------------------------------------------------
Avg {MAE:2.21, RMSE:3.02, R2: 0.51}                                 
Total Time: 30ms                               

- Results saved to runs/inference-reg/exp18
- Figs saved to runs/inference-reg/exp18/XX_plot.png
```
### ğŸ“Š Inference Visualization

---
The figure below shows the comparison between predicted flame states and ground truth over time. 
The prediction accuracy is annotated directly on the plot.

<div align="center">
  <img src= "segment_13_GRU_plot.png" width="45%" />
  <img src= "segment_12_LSTM_plot.png" width="45%" />
</div>
<p align="center">
  <b>Figure:</b> Inference results on <code>segment_13.csv</code> (by GRU)and <code>segment_12.csv</code>(by LSTM) <br>
  R2: <b>0.8</b> and <b>0.69</b> respectively.
</p>

> âš¡ Average inference latency: < 0.5 ms

## ğŸŒˆ Conclusion

------------------------
- In this work, we used limited sensor data and carefully engineered derived 
features to establish a reliable dataset for emission prediction. 
Based on this foundation, we trained an efficient prediction system that performs 
well on both validation and test datasets. The model accurately captures emission 
trends with promising metrics and low inference latency(<0.5 ms), making it suitable for
real-time deployment in operation and maintenance diagnostic systems.

- Through extensive experiments with different hyperparameters and 
neural network architectures, we identified [GRU]() as the most effective model. 
The optimal configuration â€” with [num_steps=20]() and [num_hiddens=64]() â€” achieved 
the best performance, reaching an [RÂ² = 0.8]() at valid datasets.
These results provide a $solid baseline$ for future fine-tuning and improvements.

- We hope this work can contribute to the development of gas turbine emission prediction. 
If you have better ideas or suggestions, we welcome collaboration and discussion.

  
## ğŸ“ƒ Citing

---
If you use this work in academic research, please cite it as:
@article{XX,
  title={XXX},
  author={Zebulon},
  journal={TXX},
  year={2025}
}

## ğŸ“¬ Contact

---
Questions, suggestions, or collaboration inquiries?
> ğŸ“§ Email: 18856307989@163.com.cn